Note:  You can set the email notification address on the line with the sbatch command as follows:-
       sbatch --mail-user=yourname@nsidc.org run_setup_year.sh yyyy Fxx

For multiple users, you can include a double-quoted, comma-separated list.
       
1.  Transfer all of the input files to summit
    1a. Start a processing info file, e.g. /projects/moha2290/F16_info to
    keep track of notes on files and days processed.

2.  Take note of the start doy, end doy, total doys, total number
    of input files

    The required shell scripts are all in the

    $MEASURES-BYU/CETB_process/scripts/
    
    directory.  Add this to your $PATH, or set an ENV variable with
    this location.
    
    Note that for SMM/I and SSMIS, you will generate 42 setup
    files per day and 84 *.nc CETB data files per day

3.  cd to your location of $SENSOR_scripts
    Run nc_to_gsx.sh to create script in the scripts directory
    called gsx_lb_list_summit to convert input to gsx - arguments
    SSMIS-CSU and source (F18 e.g.)
    This takes about 3-4 minutes.

4.  Verify contents of generated file with head, tail and wc -l
    (should have same number of lines as files you are expecting
    to process)

5.  From $SENSOR_scripts, do

    sbatch --mail-user=yourname@nsidc.org run_gsx.sh Fxx $CONDAENV

    to create gsx files files and verify file count in xxx_GSX directory.
    Stderr  will be written to $SENSOR_scripts/output/ directory

    5a. Use squeue --user=$USER --long to monitor the queue activity

6.  From $SENSOR_scripts, do

    run daily_file_lists.sh to create list of input files for each day in series,
    these are stored in directory $SENSOR_lists, 1 file per day

    arguments are year, start_doy, end_doy, platform i.e. yyy ddd ddd Fxx

7.  run file_3day.sh to create list of input files for NS projections for each day in series
    	arguments are yyyy ddd ddd Fxx

8.  count to confirm the correct number of files created, 2 files
    per day for total number of days

9.  use grep to check for no "such" messages in files created -
    should only be in NS files for first and last doys - this is
    useful because it will also show if there are missing days of
    files

10. use sed to edit files to remove missing file messages
    	grep -l such ../Fxx_lists/* | xargs sed -i '/such/d'

11. From $SENSOR_scripts, do

    SSMIS_make.sh to create lists for make process

    for each year to process.  Arguments are year, start_doy, end_doy, src and
    path to summit_set_pmesdr_environment.sh script, which will depend
    on where you installed the system, usually $MEASURES-BYU/src/prod

    N.B. If you run this for multiple years, they will each
    append to the end of the $SENSOR_make_list file, currently
    there is no check for this file existing to begin with, so be
    careful if you get interrupted to clean it up before
    restarting from the first year.

12. count number of lines in input file to run_make, there should
    be 4 * number of days to process

13. From $SENSOR_scripts, do

    sbatch --mail-user=yourname@nsidc.org run_make.sh Fxx /path/to/set_env

    takes 2 arguments, the sensor and the 
    path to summit_set_pmesdr_environment.sh script, which will depend
    on where you installed the system, usually $MEASURES-BYU/src/prod

    This generates make files for setup process - files
    are stored in $SENSOR_make

From this point processing should proceed by year.  (Note that 1
year of SSMIS setup files is around 15 - 17 TB, so plan
accordingly.)

14. execute SSMIS_setup_year.sh with arguments of 4-digit year
    platform and path to summit_set_pmesdr_environement.sh script,
    to generate list of commands for loadbalancer

15. sbatch run_setup_year.sh with arguments of yyyy Fxx to run 1
    year -- only run 3 of these at one time

    sbatch --mail-user=yourname@nsidc.org run_setup_year.sh YYYY Fxx /path/to/set_env

16. after completion, execute SSMIS_sir_year.sh to create list of
    sir commands for loadbalancer

17. sbatch run_sir_year.sh with yyyy and Fxx as arguments

    sbatch --mail-user=yourname@nsidc.org run_sir_year.sh YYYY Fxx /path/to/set_env

18. execute SSMIS_setup_rm_year.sh with yyyy Fxx arguments to
    create list of setup files to remove

19. sbatch run_setup_rm_year.sh yyyy Fxx, with dependency as
    follows:-

    sbatch --dependency=afterok:jobid_from_sir run_setup_rm_year.sh yyyy Fxx

20. at this point I usually edit the list of sir commands using
    sed to create the lists for further years

21. also edit the list of setup rm commands with sed to change
    year

22. Now you can proceed to chain setup, sir and setup_rm jobs
    with dependencies.


Once the processing has completed, you have to move the files
around and run the premet and spatial file generation

1.  Edit the script file_create_dirs.sh to correspond to the
    years of data - takes the platform as argument

2.  Execute the script file_move_dir.sh (yyyy, Fxx and
    type as arguments) to create a list of mv commands by year
    cat all of the output files into moving_files_all

3.  sbatch run_mv_files.sh to move the files - single argument is Fxx (src) 

4.  execute premetandspatial.sh with Fxx as argument to generate
    list for loadbalancer

5.  sbatch run_premet_cetb.sh with Fxx as the argument

6.  run manifest.sh to create the manifest list for OPS

7.  Send email to DAAC about new batch of processing, wait for
    DAAC confirmation of ingest before deleting Fxx_sir.  Save
    the Fxx_scripts directory to someplace off scratch.